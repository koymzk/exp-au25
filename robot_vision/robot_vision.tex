\documentclass[a4paper,12pt]{article}
% LuaLaTeX 日本語対応
\usepackage{luatexja}
\usepackage[ipaex]{luatexja-preset}
\usepackage{graphicx}
% LuaLaTeX-specific packages
\usepackage{fontspec}
\usepackage{luaotfload}
\usepackage{microtype}
\usepackage{tabularx}
\usepackage{titlesec}
\usepackage{geometry}
\usepackage{amsmath}
\usepackage{siunitx}
\usepackage{tikz}
\usetikzlibrary{external}
% 外部化をオンに（キャッシュ先を figures/ に指定）
\tikzexternalize[prefix=figures/]
\tikzexternalize[mode=only pdf]
\usepackage{pgfplots}
\pgfplotsset{compat=1.18}
\usepackage{float}
\usepackage{gnuplottex}
% --- redefine captions and Japanese labels ---
\usepackage[labelfont=bf]{caption}
\renewcommand{\figurename}{図}
\renewcommand{\tablename}{表}
% --------------------------------------------
\geometry{left=25mm,right=25mm,top=25mm,bottom=25mm}
\titleformat{\section}{\large\bfseries}{\thesection}{1em}{}
\titleformat{\subsection}{\normalsize\bfseries}{\thesubsection.}{1em}{}


\begin{document}

\title{ロボットビジョン　実験レポート}
\author{氏名：山崎恒 \\共同実験者：中村零 \\ 学籍番号：62221253}
\date{\today}

\maketitle

\section{アプリ概要}
% アプリの目的や機能，使用した技術などを簡潔に記述
\subsection{動機}
今回のアプリ開発の条件として、カメラから読み込んだ画像情報を利用したアプリであることが求められていた。一方、僕らチームとしては、デモ実演の際に積極的に参加者が触れたいと思うアプリを開発したいと考えていた。
そこで、カメラから読み込んだ画像情報を入力として使用する、マルチプレイプレイヤー対戦型の格闘ゲームアプリを作成することにした。このアイデアであれば、アプリ開発の条件も満たしつつ、参加者が積極的に触れたくなるアプリになると考えたからである。
\subsection{アプリの目的}
当然であるが、今回のアプリの目的は、アプリ開発の条件を満たしつつ、参加者が積極的に触れたくなるアプリを作成することである。そのために、ゲームとして面白いものとすることを特に意識して開発を行った。
\subsection{アプリの機能}
まず、今回作成したアプリのスクリーンショットを図1に示す。
\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\linewidth]{figures/app_screenshot.png}
    \caption{アプリのスクリーンショット①}
\end{figure}
図1のような画面を用意し、格闘ゲームを実装した。まず、カメラを2つ用意し、それぞれのカメラからプレイヤー1とプレイヤー2の画像を取得する。次に、各プレイヤーの動きを画像処理で解析し、パンチとガード検出する。先にHPが0になったほうが負けとなる。

\subsection{使用した技術}
今回のアプリ開発においては、以下の技術を使用した。
\begin{itemize}
    \item OpenCV：画像処理ライブラリとして使用し、カメラからの画像取得や画像処理、文字や図形の描画を行った。
    \item Mediapipe：Googleが提供する画像処理ライブラリで、姿勢推定と人物検出に使用した。
\end{itemize}

\section{自身の実装内容}
今回のアプリにおいては、画像からプレイヤーの動きを検出する部分と、ゲームのロジックや演出全般の2つに作業が分けられたため、僕は後者をメインで担当したが、お互いに双方の担当でない部分についても相談、検討、修正を積極的に行った。
\subsection{画像からプレイヤーの動きを検知する実装：工夫した点}
まずは、授業にて最近傍探索による人物見分けが紹介されていた点を踏まえて、右手ガード、左手ガード、何もしない、などを画像素材を集めHOG特徴量を抽出し、保存して、リアルタイムの映像のHOG特徴量を計算して、最近傍探索で分類する方法を試みた。しかし、リアルタイム映像のHOG特徴量が安定せず、分類精度が低かったため、ゲームとしての入力検知としては不十分であった。
そこで、解決策をを検討した結果、多種多様な服装、外見、体格のプレイヤーが想定され、また照明条件や背景も様々であることから、たとえ画像素材を大量に収集したとしても、単純な特徴量ベースの分類には限界があると感じ、より高精度な姿勢推定を用いることにした。具体的には、MediapipeのPoseモジュールを使用し、プレイヤーの関節位置を取得し、パンチやガードの動作を検出するロジックを実装した。この方法により、様々な条件下でも比較的安定した動作検出が可能となった。
また、2つのカメラを用いることによって、各プレイヤーが物理的に距離をとってプレイすることを可能にし、接触の危険性を回避するとともに、各カメラにそれぞれ1人のプレイヤーが映るように調整することで、Mediapipeでのプレイヤー検知を容易なものにした。
\subsubsection{ガードの検知}
ガードの検知については、Mediapipeで取得した関節位置について、左右それぞれについて、肘の関節位置から手首の関節位置に向かうベクトルが、xy平面上でほぼ鉛直であることを条件とした。これは、各フレームごとに判定可能であること、および閾値を用いたルールベースの分類であることから、動作が非常に高速で、リアルタイム性が求められたゲームにとって最適のものとなった。（図1左側参照）
\subsubsection{パンチの検知}
パンチの検知については、ガードの検知と異なり、単純に1フレームの画面情報から判断できるものではなく、関節位置の動きの時間変化を追跡する必要があったことから、ガードの検出に比べ難しいタスクになった。しかし、動作するPCのスペックがそれほど高くないこと、および検出にはリアルタイム性が要求されることから、機械学習といった重い処理は避けたく、こちらも関節座標の時間変化は追跡するものの、ルールベースの分類を試みた。具体的には、以下の条件をすべて満たす場合にパンチと判定するようにした。また、関節点間の距離を扱う際には、すべて肩幅で正規化を行い、カメラとの距離や、体格差に関係なく同じ閾値で安定して動作するように工夫した。
\begin{itemize}
    \item フレーム間の肩と手首のZ軸に関する正規化距離の差分が閾値以上である状態が一定時間以上続くこと
    \item 肩と手首のZ軸に関する正規化距離が閾値以上であること
    \item 最後のパンチ検出から一定時間以上経過していること
\end{itemize}
1つ目はパンチ動作の速度を捉える条件であり、2つ目はパンチ動作の到達点を捉える条件である。3つ目は連続パンチ検出を防止するための処理である。

\subsection{ゲームのロジックや演出全般の実装：工夫した点}
ゲームのロジックや演出全般の実装においては、以下の点に工夫を行った。
\subsubsection{ゲームバランスの調整}
ゲームを面白いものにする上で、ゲームバランスの調整を行った。まず、以下のルールを設定した。
\begin{itemize}
    \item パンチがガードされなかった場合、相手のHPが10減少する。
    \item ガードが成功した場合、相手のHPは減少しない
    \item 初期HPは100で、先にHPが0になったプレイヤーが敗北する。
\end{itemize}
しかしこれでは、ガードを永遠にすると絶対に負けないという致命的な欠陥があったため、ガードをスタミナ制にし、ガードをしている間スタミナが減少し、スタミナが0になるとガードができなくなるようにした。スタミナはガードをしていないときに回復するようにした。
しかし、改善されたルールでは、永遠にパンチをすると絶対に勝てるという欠陥があったため、パンチがガードされた場合について、自分のHPを5減少させるルールを追加した。これにより、ガードとパンチのバランスが取れ、戦略的なプレイが可能になった。
また、ゲーム時間の都合から、初期HPを300に変更した。
\subsubsection{視覚情報の充実}
ゲームを面白いものにする上で、視覚情報の充実を図った。具体的には、以下の要素を追加した。
\paragraph{HPバーとスタミナバーの表示} 各プレイヤーのHPとスタミナを画面上にバーで表示し、視覚的に状況を把握しやすくした。特にスタミナは円形のゲージを採用し、回復中とそれ以外とで色を替えるなど、視覚的に分かりやすく工夫した。（図2参照）
\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\linewidth]{figures/app_screenshot_2.png}
    \caption{アプリのスクリーンショット②}
\end{figure}
\paragraph{パンチ・ガードエフェクトの追加} パンチやガードが成功した際に、その成功がわかりずらいという課題があった。そこで、双方について、成功時に音声画像両方でエフェクトを表示するようにし、成功を視覚的、聴覚的に分かりやすくした。

\paragraph{人物の背景マスク} Mediapipeの人物検出機能を使用し、各プレイヤーの背景をくり抜き、背景をファンタジー世界のような画像に置き換えることで、ゲームの世界観を強化した。

\paragraph{Mediapipeの骨格表示} MediapipeのPoseモジュールを使用し、各プレイヤーの骨格をリアルタイムで表示することで、プレイヤーの動きがどうプログラムに認識されているかを視覚的にわかりやすく表示した。このゲームは最低限両肩および肘、手首の認識がされていることが不可欠であるため、プレイヤーが自分の動きが正しく認識されているかを確認しやすくするために、この機能を追加した。

\paragraph{正面映像へのこだわり}
後述する通り、カメラ映像を正面からでないものにすれば、パンチ検出の精度が向上する可能性があるが、ゲームとしての面白さを優先し、正面映像にこだわった。これは、正面映像であれば、プレイヤー同士が向かい合って戦っている感覚が強くなり、ゲームとしての没入感が向上すると考えたからである。

\section{考察}
\subsection{画像からプレイヤーの動きを検知する実装について}
今回残された課題として、パンチ動作の検出精度が十分でない点が挙げられる。これは具体的には、パンチをしていないのにパンチと判定されたり、パンチをしたのにパンチと判定されなかったりしたことが挙げられる。
この原因の究明のため、左右それぞれについて、肩と手首のx,y,z座標をリアルタイムに画面に表示するようにし、各座標の時間変化を観察した。その結果、z座標がノイズを多分に含んでおり、これがパンチ検出の誤判定の主な原因であることが分かった。Mediapipeの姿勢推定は非常に高精度であるが、特にz座標については、カメラからの距離をLiDARのようなもので直接測定しているわけではなく、2D画像からの推定であるため、特に正体している2次元画像から奥行き情報を推定することは困難であり、ノイズが多くなってしまうことが分かった。
今回はこれの改善をすることは時間制約上難しかったが、今後の課題として、z座標のノイズ除去を行うことが挙げられる。具体的には、Mediapipeを独自に改良することはとても困難であるが、複数カメラを設置し、プレイヤーに対して横向きのカメラを設置することができれば、z軸方向以外でパンチを取得することができ、大幅な検知の精度向上が見込める。また、Mediapipeの機能に固執せず、赤いグローブなどを手に装着させ、グローブのサイズを検知することなどでもパンチ検出が可能になると思われるという助言もいただいた。これらの方法も今後の課題として検討していきたい。

\subsection{ゲームのロジックや演出全般の実装について}
今回のアプリ開発では、時間制約の関係上、ゲームとして最低限楽しめるものを達成することを優先したため、リザルト画面や、タイトル画面、チュートリアル画面等の実装は行わなかった。これらを実装することで、より完成度の高いアプリになると考えられるため、今後の課題として検討していきたい。

\section{結論}
% まとめと今後の展望など
今回のアプリ開発では、実装したい機能を実現するために何が必要を柔軟に考え、実行するという貴重な経験を積むことができ、また反省を行ったたり、TAさんやテストプレイヤーの意見を聞くことで、さらなる改善方法の検討も行うことができた。この経験を活かし、今後の研究活動に活かしていきたい。

\end{document}